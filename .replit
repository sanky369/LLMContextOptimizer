modules = ["python-3.11"]

[nix]
channel = "stable-24_05"

[workflows]
runButton = "Project"

[[workflows.workflow]]
name = "Project"
mode = "parallel"
author = "agent"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "LLM Context Optimizer"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "LLM Context Optimizer Test"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "Flask Server"

[[workflows.workflow]]
name = "LLM Context Optimizer"
author = "agent"

[workflows.workflow.metadata]
agentRequireRestartOnSave = false

[[workflows.workflow.tasks]]
task = "packager.installForAll"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python cli.py attached_assets/Pasted-To-provide-long-context-to-LLMs-without-extra-tokens-or-requests-consider-these-inventive-hacks--1738754378287.txt --structure json"

[[workflows.workflow]]
name = "LLM Context Optimizer Test"
author = "agent"

[workflows.workflow.metadata]
agentRequireRestartOnSave = false

[[workflows.workflow.tasks]]
task = "packager.installForAll"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python cli.py test_input.txt --structure json"

[[workflows.workflow]]
name = "Flask Server"
author = "agent"

[workflows.workflow.metadata]
agentRequireRestartOnSave = false

[[workflows.workflow.tasks]]
task = "packager.installForAll"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python app.py"
waitForPort = 3000

[deployment]
run = ["sh", "-c", "python cli.py attached_assets/Pasted-To-provide-long-context-to-LLMs-without-extra-tokens-or-requests-consider-these-inventive-hacks--1738754378287.txt --structure json"]

[[ports]]
localPort = 3000
externalPort = 80
